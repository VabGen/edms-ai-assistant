# .env

# --- LLM Configuration ---
# URL и имя модели для генерации
LLM__GENERATIVE=http://model-generative.shared.du.iba/v1
LLM__GENERATIVE_MODEL=generative-model
# URL и имя модели для эмбеддингов
LLM__EMBEDDING=http://model-embedding.shared.du.iba/v1
LLM__EMBEDDING_MODEL=embedding-model
# API Key для LLM (если требуется)
LLM_API_KEY=

# --- LLM Runtime Configuration ---
# Температура генерации
LLM_TEMPERATURE=0.6
# Максимальное количество токенов в ответе
LLM_MAX_TOKENS=2048
# Таймаут для запроса к модели (в секундах)
LLM_TIMEOUT=120
# Количество повторных попыток в случае ошибки
LLM_MAX_RETRIES=3
# Таймаут для одного запроса (в секундах)
LLM_REQUEST_TIMEOUT=120
# Использовать потоковую передачу (streaming)
LLM_STREAM_USAGE=true
# Дополнительные заголовки для запроса (JSON строка)
# LLM_DEFAULT_HEADERS={"X-Custom-Header": "value"}
# Дополнительные параметры запроса
# LLM_DEFAULT_QUERY="param=value"
# Клиент HTTP (если нужно использовать кастомный)

# --- Embedding Runtime Configuration ---
# Таймаут для запроса к эндпоинту эмбеддингов (в секундах)
EMBEDDING_TIMEOUT=120
# Количество повторных попыток в случае ошибки для эмбеддингов
EMBEDDING_MAX_RETRIES=3
# Таймаут для одного запроса к эмбеддингам (в секундах)
EMBEDDING_REQUEST_TIMEOUT=120
# Дополнительные заголовки для запроса к эмбеддингам (JSON строка)
# EMBEDDING_DEFAULT_HEADERS={"X-Custom-Header": "value"}
# Дополнительные параметры запроса к эмбеддингам
# EMBEDDING_DEFAULT_QUERY="param=value"
# Клиент HTTP для эмбеддингов (если нужно использовать кастомный)
# Максимальная длина контекста для эмбеддингов
EMBEDDING_CTX_LENGTH=8191
# Размер чанка для обработки текста
EMBEDDING_CHUNK_SIZE=1000
# Максимальное количество повторных попыток на один запрос
EMBEDDING_MAX_RETRIES_PER_REQUEST=6

# --- EDMS Configuration ---
CHANCELLOR_NEXT_BASE_URL=http://127.0.0.1:8098

# --- Knowledge Base Configuration ---
CHROMA_PERSIST_DIR=./chroma_db

# --- Checkpoint Configuration (PostgreSQL) ---
CHECKPOINT_DB_URL=postgresql://postgres:1234@localhost:5432/postgres

# --- SQL DB Configuration ---
SQL_DB_URL=postgresql://postgres:1234@localhost:5432/postgres

# --- Application Configuration ---
API_PORT=8000
DEBUG=true

# --- Redis Configuration ---
REDIS_URL=redis://127.0.0.1:6379/0

# --- LangSmith Tracing ---
# LANGSMITH_TRACING=true
# LANGSMITH_ENDPOINT=https://api.smith.langchain.com
# LANGSMITH_API_KEY=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
# LANGSMITH_PROJECT=edms-ai-assistant

# --- Agent Configuration ---
AGENT_ENABLE_TRACING=true
AGENT_LOG_LEVEL=INFO
AGENT_MAX_RETRIES=3

# --- Logging Configuration ---
LOGGING_LEVEL=DEBUG
LOGGING_FORMAT=%(asctime)s [%(levelname)s] %(name)s: %(message)s

# --- Telemetry Configuration ---
TELEMETRY_ENABLED=true
TELEMETRY_ENDPOINT=http://127.0.0.1:8098

# --- RAG Configuration ---
RAG_BATCH_SIZE=20
RAG_CHUNK_SIZE=1200
RAG_CHUNK_OVERLAP=300
RAG_EMBEDDING_BATCH_SIZE=10

# --- Frontend URL ---
REACT_APP_API_URL=http://model-generative.shared.du.iba/v1