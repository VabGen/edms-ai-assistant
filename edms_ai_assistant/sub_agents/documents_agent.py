# edms_ai_assistant.sub_agents.documents_agent

import logging
import json
from langchain_core.tools import BaseTool
from pydantic import Field, BaseModel
from typing import Dict, Any, Optional, List
from langgraph.graph import StateGraph, END
from typing import Dict, Any
from langchain_core.messages import AIMessage, ToolMessage, HumanMessage
from edms_ai_assistant.core.sub_agents import register_agent
from edms_ai_assistant.core.orchestrator import OrchestratorState, _extract_summary_intent
from edms_ai_assistant.llm import get_chat_model
from edms_ai_assistant.tools.document import get_document_tool, search_documents_tool
from edms_ai_assistant.tools.attachment import summarize_attachment_tool, extract_and_summarize_file_async_tool
from edms_ai_assistant.utils.format_utils import format_document_response

try:
    from edms_ai_assistant.constants import SUMMARY_TYPES
except ImportError:
    SUMMARY_TYPES = {}

logger = logging.getLogger(__name__)


# ----------------------------------------------------------------------------------------------
# --- Schemas & Wrapped Tools (–û—Å—Ç–∞–≤–ª–µ–Ω—ã –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, –∫—Ä–æ–º–µ ExtractAndSummarizeFileToolWrapped - –¥–æ–±–∞–≤–ª–µ–Ω summary_type) ---
# ----------------------------------------------------------------------------------------------


class DocumentIdSchema(BaseModel):
    document_id: str = Field(description="–£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ (UUID).")


class SearchFiltersSchema(BaseModel):
    filters: Dict[str, Any] = Field(
        description="–°–ª–æ–≤–∞—Ä—å —Ñ–∏–ª—å—Ç—Ä–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."
    )


class SummarizeAttachmentSchema(BaseModel):
    document_id: str = Field(description="–£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ (UUID).")
    attachment_id: str = Field(description="–£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≤–ª–æ–∂–µ–Ω–∏—è (UUID).")
    attachment_name: str = Field(
        description="–ò–º—è —Ñ–∞–π–ª–∞ –≤–ª–æ–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ –Ω—É–∂–Ω–æ —Å—É–º–º–∏—Ä–æ–≤–∞—Ç—å."
    )
    # –î–æ–±–∞–≤–ª—è–µ–º summary_type, —á—Ç–æ–±—ã LLM –º–æ–≥ –ø–µ—Ä–µ–¥–∞—Ç—å –µ–≥–æ
    summary_type: Optional[str] = Field(description="–¢–∏–ø —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ (e.g., 'SHORT', 'DETAILED', 'LEGAL').")


class SummarizeFileSchema(BaseModel):
    file_path: str = Field(description="–õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ —Å—É–º–º–∏—Ä–æ–≤–∞—Ç—å.")
    # –î–æ–±–∞–≤–ª—è–µ–º summary_type
    summary_type: Optional[str] = Field(description="–¢–∏–ø —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ (e.g., 'SHORT', 'DETAILED', 'LEGAL').")


class ExtractAndSummarizeFileToolWrapped(BaseTool):
    """–û–±—ë—Ä–Ω—É—Ç—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –ª–æ–∫–∞–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞."""

    name: str = "extract_and_summarize_file_async_tool_wrapped"
    description: str = (
        "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ª–æ–∫–∞–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞. "
        "–¢—Ä–µ–±—É–µ—Ç file_path –∏ service_token. –ò—Å–ø–æ–ª—å–∑—É–π –°–¢–†–û–ì–û, –µ—Å–ª–∏ file_path –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ state."
    )
    args_schema: type[BaseModel] = SummarizeFileSchema
    user_token: str = Field(exclude=True)

    def _run(self, *args, **kwargs):
        raise NotImplementedError("This tool is designed for async-only invocation. Use ainvoke.")

    async def _arun(self, file_path: str, summary_type: Optional[str]) -> str:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, –∏—Å–ø–æ–ª—å–∑—É—é—â–µ–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π user_token."""
        # üìå summary_type –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –∫–∞–∫ None, –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω.
        return await extract_and_summarize_file_async_tool(
            file_path=file_path,
            service_token=self.user_token,
            summary_type=summary_type
        )

    async def ainvoke(self, input: Dict[str, Any], **kwargs) -> str:
        return await self._arun(
            file_path=input.get("file_path"),
            summary_type=input.get("summary_type"),
        )


class GetDocumentToolWrapped(BaseTool):
    # –û—Å—Ç–∞–≤–ª–µ–Ω –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    """–û–±—ë—Ä–Ω—É—Ç—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞, –ø–µ—Ä–µ–¥–∞—é—â–∏–π —Ç–æ–∫–µ–Ω."""

    name: str = "get_document_tool_wrapped"
    description: str = (
        "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ –ø–æ –µ–≥–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É (ID)."
    )
    args_schema: type[BaseModel] = DocumentIdSchema
    user_token: str = Field(exclude=True)

    def _run(self, *args, **kwargs):
        raise NotImplementedError(
            "This tool is designed for async-only invocation. Use ainvoke."
        )

    async def _arun(self, document_id: str) -> str:
        logger.info(f"–í—ã–∑–æ–≤ get_document_tool —Å document_id: {document_id}")
        return await get_document_tool(document_id, self.user_token)

    async def ainvoke(self, input: Dict[str, Any], **kwargs) -> str:
        document_id = input.get("document_id")
        if not document_id:
            raise ValueError("document_id is required")
        return await self._arun(document_id=document_id)


class SearchDocumentsToolWrapped(BaseTool):
    # –û—Å—Ç–∞–≤–ª–µ–Ω –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    """–û–±—ë—Ä–Ω—É—Ç—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –ø–µ—Ä–µ–¥–∞—é—â–∏–π —Ç–æ–∫–µ–Ω."""

    name: str = "search_documents_tool_wrapped"
    description: str = (
        "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ —Ñ–∏–ª—å—Ç—Ä–∞–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ –∏–º–µ–Ω–∏, –¥–∞—Ç–µ, —Ç–∏–ø—É)."
    )
    args_schema: type[BaseModel] = SearchFiltersSchema
    user_token: str = Field(exclude=True)

    def _run(self, *args, **kwargs):
        raise NotImplementedError(
            "This tool is designed for async-only invocation. Use ainvoke."
        )

    async def _arun(self, filters: Dict[str, Any]) -> str:
        return await search_documents_tool(filters, self.user_token)

    async def ainvoke(self, input: Dict[str, Any], **kwargs) -> str:
        filters = input.get("filters")
        if filters is None:
            raise ValueError("filters dictionary is required")
        return await self._arun(filters=filters)


class SummarizeAttachmentToolWrapped(BaseTool):
    """–û–±—ë—Ä–Ω—É—Ç—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –≤–ª–æ–∂–µ–Ω–∏—è, –ø–µ—Ä–µ–¥–∞—é—â–∏–π —Ç–æ–∫–µ–Ω."""

    name: str = "summarize_attachment_tool_wrapped"
    description: str = (
        "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –≤–ª–æ–∂–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞. "
        "–¢—Ä–µ–±—É–µ—Ç document_id, attachment_id, attachment_name –∏ summary_type. "
        "–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ, –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–∏ –≤–ª–æ–∂–µ–Ω–∏–π."
    )
    args_schema: type[BaseModel] = SummarizeAttachmentSchema
    user_token: str = Field(exclude=True)

    def _run(self, *args, **kwargs):
        raise NotImplementedError(
            "This tool is designed for async-only invocation. Use ainvoke."
        )

    async def _arun(
            self, document_id: str, attachment_id: str, attachment_name: str, summary_type: Optional[str]
    ) -> str:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, –∏—Å–ø–æ–ª—å–∑—É—é—â–µ–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π user_token."""
        tool_input = {
            "document_id": document_id,
            "attachment_id": attachment_id,
            "attachment_name": attachment_name,
            "service_token": self.user_token,
            "summary_type": summary_type  # –ü–µ—Ä–µ–¥–∞—á–∞ summary_type
        }

        return await summarize_attachment_tool.ainvoke(tool_input)

    async def ainvoke(self, input: Dict[str, Any], **kwargs) -> str:
        return await self._arun(
            document_id=input.get("document_id"),
            attachment_id=input.get("attachment_id"),
            attachment_name=input.get("attachment_name"),
            summary_type=input.get("summary_type"),
        )


# ----------------------------------------------------------------------------------------------
# --- –ù–û–í–´–ï –£–ó–õ–´ LANGGRAPH (CODE & LLM) ---
# ----------------------------------------------------------------------------------------------


async def fetch_document_data_node(state: OrchestratorState) -> Dict[str, Any]:
    """–£–∑–µ–ª, —É–ø—Ä–∞–≤–ª—è–µ–º—ã–π –∫–æ–¥–æ–º: –ø–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –¥–æ–∫—É–º–µ–Ω—Ç–µ, –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–º–µ—Ä–µ–Ω–∏–µ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ."""

    document_id = state.get("context", {}).get("document_id")
    user_token = state["user_token"]
    messages = state["messages"]

    # 1. –û–ü–†–ï–î–ï–õ–Ø–ï–ú –ò –°–û–•–†–ê–ù–Ø–ï–ú –ù–ê–ú–ï–†–ï–ù–ò–ï
    is_summary_request = state.get("is_summary_request_initial", False)

    if not is_summary_request:
        initial_query = ""
        # ‚ùó –ü–†–û–í–ï–†–ö–ê: –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ –ø–µ—Ä–≤–æ–≥–æ HumanMessage
        if messages and isinstance(messages[0], HumanMessage):
            initial_query = messages[0].content

        # 1.1. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –ø–æ –Ω–∞—á–∞–ª—å–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É
        is_summary_request = _extract_summary_intent(initial_query)

    # 1.2. –õ–û–ì–ò–ö–ê –î–õ–Ø HITL-–û–¢–í–ï–¢–ê ('3') - –ö–õ–Æ–ß–ï–í–û–ô –ú–û–ú–ï–ù–¢
    last_message_content = messages[-1].content if messages and isinstance(messages[-1], HumanMessage) else ""
    if state.get("is_hitl_active") and last_message_content.isdigit():
        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç–≤–µ—Ç - —Ü–∏—Ñ—Ä–∞, —ç—Ç–æ —è–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ HITL
        is_summary_request = True
        state["summary_type"] = SUMMARY_TYPES.get(last_message_content, "SHORT")
        logger.debug(f"HITL-–æ—Ç–≤–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω –∫–∞–∫ —è–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ. –¢–∏–ø: {state['summary_type']}.")

    # 2. –ï—Å–ª–∏ –µ—Å—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö EDMS, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–ª–∞–≥
    if state.get("file_path"):
        return {"document_data_fetched": False, "is_summary_request_initial": is_summary_request}

    if not document_id:
        # –ï—Å–ª–∏ –Ω–µ—Ç ID, –∑–∞–≤–µ—Ä—à–∞–µ–º, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–ª–∞–≥
        return {"document_data_fetched": False, "is_summary_request_initial": is_summary_request}

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
    get_doc_tool = GetDocumentToolWrapped(user_token=user_token)

    try:
        raw_result = await get_doc_tool.ainvoke({"document_id": document_id})
        doc_data = json.loads(raw_result)
        tool_result = json.dumps(doc_data, ensure_ascii=False)

        # 3. –°–û–•–†–ê–ù–Ø–ï–ú –í–õ–û–ñ–ï–ù–ò–Ø
        attachments = doc_data.get("attachmentDocument", [])

        if attachments and is_summary_request:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –≤–ª–æ–∂–µ–Ω–∏–µ (–µ—Å–ª–∏ —Ö–æ—Ç–∏–º –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å—Å—è –æ–¥–Ω–∏–º)
            attachments_to_process = [attachments[0]]
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(attachments)} –≤–ª–æ–∂–µ–Ω–∏–π. –í—ã–±—Ä–∞–Ω–æ 1 –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {attachments[0].get('name')}.")
        else:
            attachments_to_process = []
            if is_summary_request:
                logger.warning("–ó–∞–ø—Ä–æ—Å –Ω–∞ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ, –Ω–æ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤–ª–æ–∂–µ–Ω–∏–π.")

        # –°–æ–∑–¥–∞–µ–º ToolMessage —Å –ü–û–õ–ù–´–ú–ò –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏.
        tool_message = ToolMessage(
            content=tool_result,
            tool_call_id=f"doc_fetch_{document_id}",
            name="get_document_tool_wrapped"
        )

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        return {
            "document_data_fetched": True,
            "document_data_json": tool_result,
            "attachments_to_process": attachments_to_process,
            "messages": messages + [tool_message],
            "is_summary_request_initial": is_summary_request  # –ü–µ—Ä–µ—Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–ª–∞–≥!
        }

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {document_id}: {e}")
        error_msg = f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞: {type(e).__name__}."

        return {
            "document_data_fetched": False,
            "messages": messages + [AIMessage(content=error_msg)],
        }


async def summarize_attachment_node(state: OrchestratorState) -> Dict[str, Any]:
    """
    –£–∑–µ–ª, —É–ø—Ä–∞–≤–ª—è–µ–º—ã–π LLM: –≤—ã–∑—ã–≤–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –≤–ª–æ–∂–µ–Ω–∏—è.
    """
    messages = state["messages"]
    user_token = state["user_token"]
    attachments_to_process = state.get("attachments_to_process", [])
    document_id = state.get("context", {}).get("document_id")
    summary_type = state.get("summary_type")

    # –ï—Å–ª–∏ –Ω–µ—Ç –≤–ª–æ–∂–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if not attachments_to_process:
        return {"messages": messages}  # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Ñ–∏–Ω–∞–ª—É –±–µ–∑ –æ—à–∏–±–æ–∫

    attachment = attachments_to_process[0]

    # üõë –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ö–õ–Æ–ß–ï–ô: –ò—Å–ø–æ–ª—å–∑—É–µ–º 'id' –∏ 'name' –∏–∑ DTO/JSON
    attachment_id = attachment.get("id")
    attachment_name = attachment.get("name")

    if not attachment_id or not attachment_name:
        logger.warning("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤–ª–æ–∂–µ–Ω–∏—è (–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç id –∏–ª–∏ name). –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ.")
        # –£–¥–∞–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –≤–ª–æ–∂–µ–Ω–∏–µ –∏ –ø—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–π—Ç–∏ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É (–µ—Å–ª–∏ –±—ã –∏—Ö –±—ã–ª–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ)
        return {"attachments_to_process": attachments_to_process[1:]}

    llm = get_chat_model()

    # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è LLM, —á—Ç–æ–±—ã –æ–Ω –≤—ã–∑–≤–∞–ª –Ω—É–∂–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç (–≤–∫–ª—é—á–∞—è summary_type)
    system_instruction = (
            f"–¢—ã –¥–æ–ª–∂–µ–Ω –≤—ã–∑–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç 'summarize_attachment_tool_wrapped' —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏: "
            f"document_id='{document_id}', attachment_id='{attachment_id}', attachment_name='{attachment_name}'"
            + (f", summary_type='{summary_type}'" if summary_type else "") + "."
    )

    # üìå –£–ë–†–ê–ù–û: HumanMessage(content=system_instruction) - LLM –Ω–µ –Ω—É–∂–¥–∞–µ—Ç—Å—è –≤ —ç—Ç–æ–º –¥–ª—è –≤—ã–∑–æ–≤–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞

    tools_to_bind = [SummarizeAttachmentToolWrapped(user_token=user_token)]
    llm_with_tool = llm.bind_tools(
        tools_to_bind,
        tool_choice={'type': 'function', 'function': {'name': 'summarize_attachment_tool_wrapped'}}
    )

    try:
        # LLM –ø–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â—É—é –∏—Å—Ç–æ—Ä–∏—é –∏ –Ω–µ—è–≤–Ω—ã–π –≤—ã–∑–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ bind_tools
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏—à—å –∫–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç, —á—Ç–æ–±—ã –∏–Ω–∏—Ü–∏–∏—Ä–æ–≤–∞—Ç—å tool_call
        tool_call_prompt = [AIMessage(content=f"–°—É–º–º–∏—Ä—É–π –≤–ª–æ–∂–µ–Ω–∏–µ {attachment_name} –ø–æ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–º—É —Ç–∏–ø—É.")]
        response = await llm_with_tool.ainvoke(messages + tool_call_prompt)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–∑–æ–≤–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
        if hasattr(response, "tool_calls") and response.tool_calls:
            tool_call = response.tool_calls[0]

            tool_args = dict(tool_call['args'])
            # üìå –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û–ï –î–û–ë–ê–í–õ–ï–ù–ò–ï summary_type, –µ—Å–ª–∏ LLM –µ–≥–æ –Ω–µ –¥–æ–±–∞–≤–∏–ª
            if summary_type and 'summary_type' not in tool_args:
                tool_args['summary_type'] = summary_type

            tool_instance = next(t for t in tools_to_bind if t.name == tool_call["name"])
            tool_result = await tool_instance.ainvoke(tool_args)

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ: —É–¥–∞–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –≤–ª–æ–∂–µ–Ω–∏–µ –∏ –¥–æ–±–∞–≤–ª—è–µ–º ToolMessage
            new_attachments_list = attachments_to_process[1:]

            tool_message = ToolMessage(
                content=tool_result,
                tool_call_id=tool_call["id"],
                name=tool_call["name"]
            )

            # ‚ùó –î–û–ë–ê–í–õ–ï–ù –õ–û–ì –£–°–ü–ï–®–ù–û–ì–û –í–´–ó–û–í–ê
            logger.info(f"–£—Å–ø–µ—à–Ω–æ–µ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–ª–æ–∂–µ–Ω–∏—è {attachment_name}.")

            return {
                "attachments_to_process": new_attachments_list,
                "messages": messages + [tool_message],
            }
        else:
            logger.error(
                "LLM –Ω–µ –≤—ã–∑–≤–∞–ª –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –≤ summarize_attachment_node. –í–æ–∑–º–æ–∂–Ω–æ, –ø—Ä–æ–±–ª–µ–º–∞ –≤ –ø—Ä–æ–º–ø—Ç–µ/bind_tools.")
            return {"messages": messages,
                    "attachments_to_process": attachments_to_process[1:]}  # –ò–¥–µ–º –¥–∞–ª—å—à–µ –±–µ–∑ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ —É–∑–ª–µ summarize_attachment_node: {e}")
        error_msg = f"–û—à–∏–±–∫–∞ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –≤–ª–æ–∂–µ–Ω–∏—è: {type(e).__name__}."

        # –î–æ–±–∞–≤–ª—è–µ–º –æ—à–∏–±–∫—É –≤ –∏—Å—Ç–æ—Ä–∏—é –∏ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
        return {
            "attachments_to_process": attachments_to_process[1:],
            "messages": messages + [AIMessage(content=error_msg)],
        }


async def summarize_file_node(state: OrchestratorState) -> Dict[str, Any]:
    """
    –£–∑–µ–ª, —É–ø—Ä–∞–≤–ª—è–µ–º—ã–π LLM: –≤—ã–∑—ã–≤–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.
    """
    messages = state["messages"]
    user_token = state["user_token"]
    file_path = state["file_path"]
    summary_type = state.get("summary_type")

    llm = get_chat_model()

    tools_to_bind = [ExtractAndSummarizeFileToolWrapped(user_token=user_token)]
    llm_with_tool = llm.bind_tools(
        tools_to_bind,
        tool_choice={'type': 'function', 'function': {'name': 'extract_and_summarize_file_async_tool_wrapped'}}
    )

    try:
        # LLM –ø–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â—É—é –∏—Å—Ç–æ—Ä–∏—é –∏ –Ω–µ—è–≤–Ω—ã–π –≤—ã–∑–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ bind_tools
        tool_call_prompt = [AIMessage(content=f"–°—É–º–º–∏—Ä—É–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø–æ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–º—É —Ç–∏–ø—É.")]
        response = await llm_with_tool.ainvoke(messages + tool_call_prompt)

        if hasattr(response, "tool_calls") and response.tool_calls:
            tool_call = response.tool_calls[0]

            tool_args = dict(tool_call['args'])
            # üìå –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û–ï –î–û–ë–ê–í–õ–ï–ù–ò–ï summary_type
            if summary_type and 'summary_type' not in tool_args:
                tool_args['summary_type'] = summary_type

            tool_instance = next(t for t in tools_to_bind if t.name == tool_call["name"])
            tool_result = await tool_instance.ainvoke(tool_args)

            tool_message = ToolMessage(
                content=tool_result,
                tool_call_id=tool_call["id"],
                name=tool_call["name"]
            )

            return {
                "messages": messages + [tool_message],
                "file_path": None,  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º, —á—Ç–æ–±—ã –Ω–µ –≤—ã–∑—ã–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ
            }
        else:
            logger.error("LLM –Ω–µ –≤—ã–∑–≤–∞–ª –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –≤ summarize_file_node.")
            return {"messages": messages, "file_path": None}

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ —É–∑–ª–µ summarize_file_node: {e}")
        error_msg = f"–û—à–∏–±–∫–∞ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞: {type(e).__name__}."

        return {
            "messages": messages + [AIMessage(content=error_msg)],
            "file_path": None,
        }


async def generate_final_response_node(state: OrchestratorState) -> Dict[str, Any]:
    """
    –£–∑–µ–ª, —É–ø—Ä–∞–≤–ª—è–µ–º—ã–π LLM: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π, –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç.
    """
    messages = state["messages"]
    is_summary_request = state.get("is_summary_request_initial", False)

    # ‚ùó –õ–û–ì–ò–ö–ê –§–ò–õ–¨–¢–†–ê–¶–ò–ò –î–ê–ù–ù–´–• –ü–ï–†–ï–î –û–¢–ü–†–ê–í–ö–û–ô LLM (–û—Å—Ç–∞–≤–ª–µ–Ω–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π - –æ–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞)
    if not is_summary_request and state.get("document_data_json"):

        full_data = json.loads(state["document_data_json"])

        if "attachmentDocument" in full_data:
            full_data.pop("attachmentDocument")
            logger.debug("–í–æ–ø—Ä–æ—Å –Ω–µ –æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–∏ (—Ñ–∏–ª—å—Ç—Ä –ø–µ—Ä–µ–¥ —Ñ–∏–Ω–∞–ª—å–Ω—ã–º LLM). –£–¥–∞–ª—è–µ–º 'attachmentDocument'.")

        cleaned_tool_result = json.dumps(full_data, ensure_ascii=False)
        cleaned_tool_message = ToolMessage(
            content=cleaned_tool_result,
            tool_call_id=f"doc_fetch_cleaned_{full_data.get('id')}",
            name="get_document_tool_wrapped"
        )

        new_messages = []
        for msg in messages:
            if isinstance(msg, ToolMessage) and msg.name == "get_document_tool_wrapped" and msg.content == state[
                "document_data_json"]:
                new_messages.append(cleaned_tool_message)
            else:
                new_messages.append(msg)

        final_messages_for_llm = new_messages
    else:
        final_messages_for_llm = messages

    llm = get_chat_model()

    # üìå –§–ò–ù–ê–õ–¨–ù–´–ô –°–¢–†–û–ì–ò–ô –ü–†–û–ú–ü–¢
    final_instruction = (
        "–¢—ã ‚Äî —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥-–∞–≥–µ–Ω—Ç, –æ—Ç–≤–µ—á–∞—é—â–∏–π –∑–∞ —Ä–∞–±–æ—Ç—É —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –°–≠–î. "
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –¥–∞—Ç—å **—Ñ–∏–Ω–∞–ª—å–Ω—ã–π, –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏ —Å—Ç—Ä–æ–≥–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π** –æ—Ç–≤–µ—Ç –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –≤—Å–µ–π –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π, –≤–∫–ª—é—á–∞—è –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è. "

        "### –ü–†–ê–í–ò–õ–ê –ì–ï–ù–ï–†–ê–¶–ò–ò –û–¢–í–ï–¢–ê (Markdown)\n"
        "1. **–†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–¨ (–ü–†–ò–û–†–ò–¢–ï–¢):** –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω **–°–¢–†–û–ì–û** —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –∏—Å—Ö–æ–¥–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É. –ï—Å–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞–ª–∏ —Ç–æ–ª—å–∫–æ –æ–± –∞–≤—Ç–æ—Ä–µ, –æ—Ç–≤–µ—á–∞–µ—à—å —Ç–æ–ª—å–∫–æ –æ–± –∞–≤—Ç–æ—Ä–µ.\n"
        "2. **–°–¢–†–£–ö–¢–£–†–ê:** –ò—Å–ø–æ–ª—å–∑—É–π –∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏ –∏ **–∂–∏—Ä–Ω—ã–π —à—Ä–∏—Ñ—Ç** –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –¥–µ—Ç–∞–ª–µ–π.\n"
        "3. **–°–û–î–ï–†–ñ–ê–ù–ò–ï –í–õ–û–ñ–ï–ù–ò–ô:** –†–∞–∑–¥–µ–ª –æ –≤–ª–æ–∂–µ–Ω–∏—è—Ö –≤–∫–ª—é—á–∞–π **–¢–û–õ–¨–ö–û** –µ—Å–ª–∏: –∞) —Ç—ã –ø–æ–ª—É—á–∏–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –≤–ª–æ–∂–µ–Ω–∏—è –ò–õ–ò –±) –≤–æ–ø—Ä–æ—Å —è–≤–Ω–æ –∫–∞—Å–∞–ª—Å—è –≤–ª–æ–∂–µ–Ω–∏–π.\n"
        "4. **–ó–ê–ü–†–ï–¢–´:** –ö–∞—Ç–µ–≥–æ—Ä–∏—á–µ—Å–∫–∏ –∑–∞–ø—Ä–µ—â–µ–Ω–æ —É–ø–æ–º–∏–Ω–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —à–∞–≥–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏–∑–≤–ª–µ—á—å', '–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å') –∏–ª–∏ –ª—é–±—É—é —Å–ª—É–∂–µ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é (UUID, ID, —Ä–∞–∑–º–µ—Ä—ã, –¥–∞—Ç—ã)."
    )

    final_prompt = [HumanMessage(content=final_instruction)] + final_messages_for_llm

    try:
        response = await llm.ainvoke(final_prompt)
        raw_content = response.content or ""

        # üìå –ò–°–ü–û–õ–¨–ó–£–ï–ú –§–û–†–ú–ê–¢–¢–ï–† (post-processing)
        formatted_content = format_document_response(raw_content)
        final_result = formatted_content if formatted_content else raw_content

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")
        final_result = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."

    return {
        "final_response": final_result,
        "messages": [AIMessage(content=final_result)],
        "subagent_result": final_result,
        "called_subagent": "documents_agent",
        "attachments_to_process": [],  # –û—á–∏—Å—Ç–∫–∞
    }


def route_next_step(state: Dict[str, Any]) -> str:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥: —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–ª–∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç,
    –æ–ø–∏—Ä–∞—è—Å—å –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –Ω–∞ —Ñ–ª–∞–≥–∏, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —É–∑–ª–∞—Ö.
    """

    is_summary_request = state.get("is_summary_request_initial", False)
    file_path = state.get("file_path")
    attachments = state.get("attachments_to_process", [])

    # ‚ùó –î–û–ë–ê–í–õ–ï–ù –õ–û–ì –î–õ–Ø –ü–û–ù–ò–ú–ê–ù–ò–Ø –ú–ê–†–®–†–£–¢–ò–ó–ê–¶–ò–ò
    logger.debug(
        f"Route check: summary={is_summary_request}, file_path={file_path}, attachments_count={len(attachments)}")

    # --- –õ–û–ì–ò–ö–ê –ú–ê–†–®–†–£–¢–ò–ó–ê–¶–ò–ò ---

    # 1. –ï—Å–ª–∏ –µ—Å—Ç—å –õ–û–ö–ê–õ–¨–ù–´–ô —Ñ–∞–π–ª –ò –∑–∞–ø—Ä–æ—à–µ–Ω–æ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ (PRIORITY)
    if file_path and is_summary_request:
        return "summarize_file"

    # 2. –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ –°–£–ú–ú–ò–†–û–í–ê–ù–ò–ï, –ò –µ—Å—Ç—å –≤–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if is_summary_request and attachments:
        return "summarize_attachment"

    # 3. –í–æ –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö:
    # - –ù–µ—Ç –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ.
    # - –ï—Å—Ç—å –∑–∞–ø—Ä–æ—Å, –Ω–æ –Ω–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–ª–æ–∂–µ–Ω–∏–π/—Ñ–∞–π–ª–∞.
    # - –ù—É–∂–µ–Ω —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º.
    return "generate_final_response"


# ----------------------------------------------------------------------------------------------
# --- LANGGRAPH ASSEMBLY (–û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞) ---
# ----------------------------------------------------------------------------------------------

@register_agent("documents_agent")
def create_documents_agent_graph():
    """–°–æ–∑–¥–∞–µ—Ç –∏ –∫–æ–º–ø–∏–ª–∏—Ä—É–µ—Ç –≥—Ä–∞—Ñ –∞–≥–µ–Ω—Ç–∞ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º."""

    nodes_map = {
        "fetch_data": fetch_document_data_node,
        "summarize_attachment": summarize_attachment_node,
        "summarize_file": summarize_file_node,
        "generate_final_response": generate_final_response_node,
    }

    workflow = StateGraph(OrchestratorState)

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–∑–ª–æ–≤
    for name, node in nodes_map.items():
        workflow.add_node(name, node)

    # 1. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞—á–∞–ª—å–Ω–æ–π —Ç–æ—á–∫–∏
    workflow.set_entry_point("fetch_data")

    # 2. –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö (–ö–û–î)
    workflow.add_conditional_edges(
        "fetch_data",
        route_next_step,
        {
            "summarize_file": "summarize_file",
            "summarize_attachment": "summarize_attachment",
            "generate_final_response": "generate_final_response",
        }
    )

    # 3. –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –ø–æ—Å–ª–µ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞ (–≤—Å–µ–≥–¥–∞ –∫ —Ñ–∏–Ω–∞–ª—É)
    workflow.add_edge("summarize_file", "generate_final_response")

    # 4. –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –ø–æ—Å–ª–µ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –≤–ª–æ–∂–µ–Ω–∏—è (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–ª–æ–∂–µ–Ω–∏–π, –Ω–æ –ø–æ–∫–∞ –∏–¥–µ–º –∫ —Ñ–∏–Ω–∞–ª—É)
    # –ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –í–°–ï –≤–ª–æ–∂–µ–Ω–∏—è, –∑–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —É—Å–ª–æ–≤–Ω–∞—è –ø–µ—Ç–ª—è –æ–±—Ä–∞—Ç–Ω–æ –∫ summarize_attachment.
    # –ù–æ —Ç–∞–∫ –∫–∞–∫ –≤—ã –æ–≥—Ä–∞–Ω–∏—á–∏–ª–∏ —Å–ø–∏—Å–æ–∫ –æ–¥–Ω–∏–º —ç–ª–µ–º–µ–Ω—Ç–æ–º, –∏–¥–µ–º –∫ —Ñ–∏–Ω–∞–ª—É.
    workflow.add_edge("summarize_attachment", "generate_final_response")

    # 5. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ
    workflow.add_edge("generate_final_response", END)

    return workflow.compile()